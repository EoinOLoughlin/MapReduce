Assignment Brief: The goal of this assignment is to implement and test some modifications to the attached sample map reduce program, as follows:

1. The program should be passed a list of text files to be processed via the command line. Use a number of large text or log files for testing your program. You can download files like these from the internet. There are also some free online PDF to text file converters available that will convert PDF files into text files e.g. easypdf.com, these can be useful if you have some large PDF files and want to convert them to text format for testing purposes.

2. You can remove the source code related to Approach 1 (Brute Force) and Approach 2 (Single Threaded Map Reduce) from the program, as this will not be required for this assignment. Modify the Approach 3 (Multithreaded) source code so that only proper individual words, separated by white space, are included in the output of the map phase. Words that include punctuation characters or other non-text symbols or numbers should be filtered and modified to only include the word itself. For example, something like the word "finished," should be modified and included in the mapped items as the word "finished".

3. Implement some accurate mechanism that outputs how long it takes, measured in milliseconds, to run the various parts of the program, this provides a measure of the baseline performance of each phase of the program with a given set of large text files. Run a number of tests at this point to measure how long the different phases of the program take using the set of large text files you have downloaded for this purpose. These results will be used later as a baseline to see if modifications to the threading strategy can improve the overall performance of the program.

4. Modify the main program to implement and test a different threading strategy for the map phase of the program. The sample program provided uses a thread per file for the map phase. Modify the program to instead use a separate thread per a configurable number of lines of text. For example, if there were 20,000 lines of text in total, and you specified that the program should use 1000 lines of text per map thread, then this would result in the creation of 20 threads to perform the map phase of the program. The number of text lines per thread should be passed in the command line, so that different values can be tested and compared.

5. Further modify the program to implement and test a different threading strategy for the reduce phase of the program. The sample program provided uses a thread per individual word for the reduce phase. Modify the program to instead use a separate thread per a configurable number of grouped items, this is the output from the group phase. For example, if there were 3000 individual words, used as keys, in the map containing the output from the group phase, and you specified that the program should use 100 words per reduce thread, then this would result in the creation of 30 threads to perform the reduce phase of the program. The number of words per thread should be passed in the command line, so that different values can be tested and compared.

6. Run a number of tests that use different values for the number of lines of text per map thread and the number of grouped items (individual words) per reduce thread. Compare the results with the original version of the program. What values work well and give the best performance for the set of large files that you used for testing purposes?

Source Code:
import java.util.ArrayList;
import java.util.HashMap;
import java.util.Iterator;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.io.IOException;
import java.io.File;
import java.io.FileReader;
import java.io.BufferedReader;
import java.util.Scanner;

public class MapReduceFiles {

  public static void main(String[] args) {

    if (args.length < 3) {
      System.err.println("usage: java MapReduceFiles file1.txt file2.txt file3.txt");

    }

    Map<String, String> input = new HashMap<String, String>();
    try {
      input.put(args[0], readFile(args[0]));
      input.put(args[1], readFile(args[1]));
      input.put(args[2], readFile(args[2]));
    }
    catch (IOException ex)
    {
        System.err.println("Error reading files...\n" + ex.getMessage());
        ex.printStackTrace();
        System.exit(0);
    }

    // APPROACH #3: Distributed MapReduce
    {
      final Map<String, Map<String, Integer>> output = new HashMap<String, Map<String, Integer>>();

      // MAP:

      final List<MappedItem> mappedItems = new LinkedList<MappedItem>();

      final MapCallback<String, MappedItem> mapCallback = new MapCallback<String, MappedItem>() {
        @Override
        public synchronized void mapDone(String file, List<MappedItem> results) {
          mappedItems.addAll(results);
        }
      };

      List<Thread> mapCluster = new ArrayList<Thread>(input.size());

      Iterator<Map.Entry<String, String>> inputIter = input.entrySet().iterator();
      while(inputIter.hasNext()) {
        Map.Entry<String, String> entry = inputIter.next();
        final String file = entry.getKey();
        final String contents = entry.getValue();

        Thread t = new Thread(new Runnable() {
          @Override
          public void run() {
            map(file, contents, mapCallback);
          }
        });
        mapCluster.add(t);
        t.start();
      }

      // wait for mapping phase to be over:
      for(Thread t : mapCluster) {
        try {
          t.join();
        } catch(InterruptedException e) {
          throw new RuntimeException(e);
        }
      }

      // GROUP:

      Map<String, List<String>> groupedItems = new HashMap<String, List<String>>();

      Iterator<MappedItem> mappedIter = mappedItems.iterator();
      while(mappedIter.hasNext()) {
        MappedItem item = mappedIter.next();
        String word = item.getWord();
        String file = item.getFile();
        List<String> list = groupedItems.get(word);
        if (list == null) {
          list = new LinkedList<String>();
          groupedItems.put(word, list);
        }
        list.add(file);
      }

      // REDUCE:

      final ReduceCallback<String, String, Integer> reduceCallback = new ReduceCallback<String, String, Integer>() {
        @Override
        public synchronized void reduceDone(String k, Map<String, Integer> v) {
          output.put(k, v);
        }
      };

      List<Thread> reduceCluster = new ArrayList<Thread>(groupedItems.size());

      Iterator<Map.Entry<String, List<String>>> groupedIter = groupedItems.entrySet().iterator();
      while(groupedIter.hasNext()) {
        Map.Entry<String, List<String>> entry = groupedIter.next();
        final String word = entry.getKey();
        final List<String> list = entry.getValue();

        Thread t = new Thread(new Runnable() {
          @Override
          public void run() {
            reduce(word, list, reduceCallback);
          }
        });
        reduceCluster.add(t);
        t.start();
      }

      // wait for reducing phase to be over:
      for(Thread t : reduceCluster) {
        try {
          t.join();
        } catch(InterruptedException e) {
          throw new RuntimeException(e);
        }
      }

      System.out.println(output);
    }
  }

  public static void map(String file, String contents, List<MappedItem> mappedItems) {

    String[] words = contents.trim().split("\\s+");
    
   

    for(String word: words) {
      mappedItems.add(new MappedItem(word, file));
    }
  }

  public static void reduce(String word, List<String> list, Map<String, Map<String, Integer>> output) {
    Map<String, Integer> reducedList = new HashMap<String, Integer>();
    for(String file: list) {
      Integer occurrences = reducedList.get(file);
      if (occurrences == null) {
        reducedList.put(file, 1);
      } else {
        reducedList.put(file, occurrences.intValue() + 1);
      }
    }
    output.put(word, reducedList);
  }

  public static interface MapCallback<E, V> {

    public void mapDone(E key, List<V> values);
  }

  public static void map(String file, String contents, MapCallback<String, MappedItem> callback) {
    String[] words = contents.trim().split("\\s+");
    List<MappedItem> results = new ArrayList<MappedItem>(words.length);
    for(String word: words) {
      results.add(new MappedItem(word, file));
    }
    callback.mapDone(file, results);
  }

  public static interface ReduceCallback<E, K, V> {

    public void reduceDone(E e, Map<K,V> results);
  }

  public static void reduce(String word, List<String> list, ReduceCallback<String, String, Integer> callback) {

    Map<String, Integer> reducedList = new HashMap<String, Integer>();
    for(String file: list) {
      Integer occurrences = reducedList.get(file);
      if (occurrences == null) {
        reducedList.put(file, 1);
      } else {
        reducedList.put(file, occurrences.intValue() + 1);
      }
    }
    callback.reduceDone(word, reducedList);
  }

  private static class MappedItem {

    private final String word;
    private final String file;

    public MappedItem(String word, String file) {
      this.word = word;
      this.file = file;
    }

    public String getWord() {
      return word;
    }

    public String getFile() {
      return file;
    }

    @Override
    public String toString() {
      return "[\"" + word + "\",\"" + file + "\"]";
    }
  }

  private static String readFile(String pathname) throws IOException {
    File file = new File(pathname);
    StringBuilder fileContents = new StringBuilder((int) file.length());
    Scanner scanner = new Scanner(new BufferedReader(new FileReader(file)));
    String lineSeparator = System.getProperty("line.separator");

    try {
      if (scanner.hasNextLine()) {
        fileContents.append(scanner.nextLine());
      }
      while (scanner.hasNextLine()) {
        fileContents.append(lineSeparator + scanner.nextLine());
      }
      return fileContents.toString();
    } finally {
      scanner.close();
    }
  }

}